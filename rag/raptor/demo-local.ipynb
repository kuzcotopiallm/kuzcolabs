{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c90ce33-352e-4473-a5bf-6dba8203e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a822006a-ff7a-4020-90bd-72fb2d406376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-111111111111111111111111111111111111111111111111'\n",
    "os.environ['OPENAI_API_BASE']='http://127.0.0.1:5000/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c287552-5c0d-49c5-b6ca-be0d0fc4896c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WizardLM-2-7B-exl2-8_0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_info_url = 'http://127.0.0.1:5000/v1/internal/model/info'\n",
    "resp = requests.get(model_info_url)\n",
    "_model_name = resp.json()['model_name']\n",
    "print(_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a14c0a-94b0-47f6-afab-720b75d32446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cd8c6-d405-4dfe-8897-46108e6a6af7",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d7d995-7beb-40b5-9a44-afd350b7d221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wife of a rich man fell sick, and as she felt that her end\n",
      "was drawing near, she called her only\n"
     ]
    }
   ],
   "source": [
    "# Cinderella story defined in sample.txt\n",
    "filename = \"ponzi\"\n",
    "filename = \"state_of_the_union\"\n",
    "filename = \"paul_graham_essay\"\n",
    "filename = \"sample\"\n",
    "with open(f'demo/{filename}.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d51ebd-5597-4fdd-8c37-32636395081b",
   "metadata": {},
   "source": [
    "1) **Building**: RAPTOR recursively embeds, clusters, and summarizes chunks of text to construct a tree with varying levels of summarization from the bottom up. You can create a tree from the text in 'sample.txt' using `RA.add_documents(text)`.\n",
    "\n",
    "2) **Querying**: At inference time, the RAPTOR model retrieves information from this tree, integrating data across lengthy documents at different abstraction levels. You can perform queries on the tree with `RA.answer_question`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f58830-9004-48a4-b50e-61a855511d24",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3753fcf9-0a8e-4ab3-bf3a-6be38ef6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:05:41,585 - Loading faiss with AVX2 support.\n",
      "2024-05-04 07:05:41,602 - Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6c3fdc-80b1-4733-a051-979d28e7fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_raptor import EmbeddingModel, QAModel, SummarizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052c5fc1-6728-463e-943f-7c1c8c20e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAC2 = RetrievalAugmentationConfig(summarization_model=SummarizationModel(), qa_model=QAModel(), embedding_model=EmbeddingModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd26b5c0-7dc4-4404-a355-5f5a77d57215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:05:41,936 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <local_raptor.SummarizationModel object at 0x7f40196f6310>\n",
      "            Embedding Models: {'EMB': <local_raptor.EmbeddingModel object at 0x7f40196f61d0>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-05-04 07:05:41,937 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <local_raptor.SummarizationModel object at 0x7f40196f6310>\n",
      "            Embedding Models: {'EMB': <local_raptor.EmbeddingModel object at 0x7f40196f61d0>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-05-04 07:05:41,937 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <local_raptor.SummarizationModel object at 0x7f40196f6310>\n",
      "            Embedding Models: {'EMB': <local_raptor.EmbeddingModel object at 0x7f40196f61d0>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <local_raptor.EmbeddingModel object at 0x7f40196f61d0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <local_raptor.QAModel object at 0x7f4019bf9dd0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "RA2 = RetrievalAugmentation(config=RAC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1952912-6e80-4bbd-9057-0d8af95abd39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:05:41,945 - Creating Leaf Nodes\n",
      "2024-05-04 07:05:42,068 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,159 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,243 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,327 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,414 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,497 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,577 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,659 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,741 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,826 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,908 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:42,989 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,071 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,163 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,250 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,338 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,432 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,525 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,607 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,690 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,777 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,862 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:43,945 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,033 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,113 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,205 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,298 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,382 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,467 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,555 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,648 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,735 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,795 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,878 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,960 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:44,962 - Created 35 Leaf Embeddings\n",
      "2024-05-04 07:05:44,962 - Building All Nodes\n",
      "2024-05-04 07:05:44,969 - Using Cluster TreeBuilder\n",
      "2024-05-04 07:05:44,969 - Constructing Layer 0\n",
      "2024-05-04 07:05:51,009 - Summarization Length: 100\n",
      "2024-05-04 07:05:53,079 - Node Texts Length: 862, Summarized Text Length: 91\n",
      "2024-05-04 07:05:53,187 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:55,160 - Node Texts Length: 676, Summarized Text Length: 87\n",
      "2024-05-04 07:05:55,253 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:57,167 - Node Texts Length: 572, Summarized Text Length: 90\n",
      "2024-05-04 07:05:57,252 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:05:59,168 - Node Texts Length: 563, Summarized Text Length: 90\n",
      "2024-05-04 07:05:59,258 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:06:01,144 - Node Texts Length: 376, Summarized Text Length: 90\n",
      "2024-05-04 07:06:01,236 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:06:03,096 - Node Texts Length: 232, Summarized Text Length: 92\n",
      "2024-05-04 07:06:03,189 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-04 07:06:03,190 - Constructing Layer 1\n",
      "2024-05-04 07:06:03,190 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 1\n",
      "2024-05-04 07:06:03,191 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <local_raptor.EmbeddingModel object at 0x7f40196f61d0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# huggingface http out\n",
    "RA2.add_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09721e90-c492-41c4-9a34-74c7ee718e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:06:03,194 - Using collapsed_tree\n",
      "2024-05-04 07:06:03,245 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Cinderella reached her happy ending through a combination of her own resilience and kindness, the magical intervention of her animal allies, and the generosity of a benevolent figure. Here's a comprehensive summary of how she reached her fairy tale conclusion:\n",
      "\n",
      "1. **Resilience and Kindness**: Despite being mistreated by her stepmother and stepsisters, Cinderella endures her situation with grace and kindness. Her gentle nature is rewarded when she receives assistance from magical creatures, including a white dove, a white pigeon, and a white bird perched on a hazel tree.\n",
      "\n",
      "2. **The Magic of the Bird**: The magical bird, which may be a fairy godmother in disguise, first appears when Cinderella's father goes to the market. The bird throws down a beautiful dress and glass slippers to Cinderella, allowing her to attend the ball where she meets the prince. This act of kindness sets the stage for the magical transformation that follows.\n",
      "\n",
      "3. **The Ball**: At the ball, Cinderella captivates the prince with her beauty and charm. The king's son dances only with her, ignoring the advances of her step-s\n"
     ]
    }
   ],
   "source": [
    "question = \"How did Cinderella reach her happy ending?\"\n",
    "\n",
    "answer = RA2.answer_question(question=question)\n",
    "\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3cf12c-e4f5-43cb-9360-052aacc34382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:06:07,237 - Using collapsed_tree\n",
      "2024-05-04 07:06:07,287 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Cinderella's general state of mind throughout the classic tale is one of resilience, optimism, and grace despite the adversity she faces. She is subjected to a life of servitude by her cruel stepmother and stepsisters, who treat her with contempt and disregard her feelings. Despite being stripped of her former life as a princess and being forced to wear drab clothes and perform menial tasks, Cinderella maintains her inner dignity and kindness.\n",
      "\n",
      "Her state of mind is characterized by several key traits:\n",
      "\n",
      "1. **Resilience**: Cinderella endures her harsh treatment without complaint. She continues to perform her duties with diligence and does not let her situation break her spirit.\n",
      "\n",
      "2. **Empathy and Forgiveness**: Despite the mistreatment she receives, Cinderella shows empathy towards her stepmother and stepsisters, praying for them and wishing for their well-being when she receives her magical transformation.\n",
      "\n",
      "3. **Optimism**: Cinderella clings to hope, as evidenced by her repeated visits to her mother's grave, where she expresses her wishes for a better life. Her optimism is reward\n"
     ]
    }
   ],
   "source": [
    "question = \"What would you say is Cinderella general state of mind?\"\n",
    "\n",
    "answer = RA2.answer_question(question=question)\n",
    "\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfff2e2-4912-45e1-9402-75248b8ecf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:06:11,224 - Using collapsed_tree\n",
      "2024-05-04 07:06:11,273 - HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The tale of Cinderella, as it is traditionally told, is a story of transformation through magic and the triumph of kindness and grace over cruelty. However, if we are to consider changes that Cinderella could make to improve her standing in life within the context of the story, while still maintaining the essence of the fairy tale, here are some recommendations that align with her character and the themes of the story:\n",
      "\n",
      "1. **Self-Advocacy and Confidence**: Cinderella should learn to stand up for herself and assert her worth. This doesn't necessarily mean confronting her stepmother and stepsisters directly (as they are depicted as being beyond reason), but perhaps finding allies or seeking help from a trusted figure who could advocate on her behalf.\n",
      "\n",
      "2. **Education and Skills**: Cinderella could focus on acquiring new skills or improving her education. This could make her more valuable to her family and potentially open opportunities for employment or a better marriage prospect, assuming the setting allows for such choices.\n",
      "\n",
      "3. **Social Networking**: Building relationships with kind and generous people could help Cinderella. She could be more open to forming connections with those who treat her well, which could lead\n"
     ]
    }
   ],
   "source": [
    "question = \"What changes would you recommend to Cinderella to improve her standing in life?\"\n",
    "\n",
    "answer = RA2.answer_question(question=question)\n",
    "\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11e38d-db8d-4a5e-9ec6-3bdb83dfa2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4dd5055-fc56-465b-bc7e-363a6a1daed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The llm_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext llm_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext llm_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df4dba94-e4eb-4dbd-9774-f070674d8023",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%llm_magic_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02072153-9d9e-4151-a004-83f07c45b70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-raptor",
   "language": "python",
   "name": "venv-raptor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
