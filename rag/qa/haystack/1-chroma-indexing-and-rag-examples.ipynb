{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5f6e31-36eb-4e3a-8da1-a793c674c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data files from the Github repo\n",
    "# !curl -sL https://github.com/deepset-ai/haystack-core-integrations/tarball/main -o main.tar\n",
    "# !mkdir main\n",
    "# !tar xf main.tar -C main --strip-components 1\n",
    "# !mv main/integrations/chroma/example/data .\n",
    "\n",
    "# https://github.com/deepset-ai/haystack-cookbook/blob/main/notebooks/chroma-indexing-and-rag-examples.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f4c06c-3098-4db0-82d7-c1c9c2006002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 36}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "\n",
    "file_paths = [\"data\" / Path(name) for name in os.listdir(\"data\")]\n",
    "\n",
    "# Chroma is used in-memory so we use the same instances in the two pipelines below\n",
    "document_store = ChromaDocumentStore()\n",
    "\n",
    "indexing = Pipeline()\n",
    "indexing.add_component(\"converter\", TextFileToDocument())\n",
    "indexing.add_component(\"writer\", DocumentWriter(document_store))\n",
    "indexing.connect(\"converter\", \"writer\")\n",
    "indexing.run({\"converter\": {\"sources\": file_paths}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc513515-07a8-45e4-b69b-726b9e140662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "from haystack.components.generators import HuggingFaceTGIGenerator, OpenAIGenerator\n",
    "from haystack.components.builders import PromptBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79048a40-3035-4d6b-aa96-f8bd5570ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the query based on the provided context.\n",
    "If the context does not contain the answer, say 'Answer not found'.\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "  {{ doc.content }}\n",
    "{% endfor %}\n",
    "query: {{query}}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953f6c25-629a-4dce-a4c7-bef8ed5a6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_builder = PromptBuilder(template=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946f14ba-6352-4bce-a9cd-cf5070520bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "# llm.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a4a4c-54a4-4eb9-9747-6bb75b71ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-111111111111111111111111111111111111111111111111'\n",
    "os.environ['OPENAI_API_BASE']='http://127.0.0.1:5000/v1'\n",
    "# os.environ['OPENAI_API_BASE']='http://127.0.0.1:8000/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbee658-61f1-40f9-ba2c-3a72b192e3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99e92f0-fef1-4c32-a7e8-94a74d6155f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.2-8.0bpw-h8-exl2-2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_info_url = 'http://127.0.0.1:5000/v1/internal/model/info'\n",
    "resp = requests.get(model_info_url)\n",
    "model = resp.json()['model_name']\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44579068-0876-4f9f-a32b-3935eb120be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0557fa57-0922-48dc-bcfa-ec5c7b83379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAIGenerator(api_base_url=os.getenv('OPENAI_API_BASE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a80736b-8233-4bcc-a336-d558acfbfac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querying = Pipeline()\n",
    "querying.add_component(\"retriever\", ChromaQueryTextRetriever(document_store))\n",
    "querying.add_component(\"prompt_builder\", prompt_builder)\n",
    "querying.add_component(\"llm\", llm)\n",
    "\n",
    "querying.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "querying.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb0ca77-c141-4063-aa54-51eb0bddb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should I write documentation for my plugin?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b1f420-900d-4188-867f-83f0fd765e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = querying.run({\n",
    "    \"retriever\": {\"query\": query, \"top_k\": 3},\n",
    "    \"prompt_builder\": {\"query\": query},\n",
    "    \"llm\":{\"generation_kwargs\": {\"max_tokens\": 2000}}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c9c47b-ac0a-4f55-9df7-7d47618a5fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it is strongly recommended to write documentation for your plugin. This will make it easier for other users to understand and use your plugin. You can use Vim's built-in help system to document your functions, variables, and commands. The documentation should explain what your plugin does, how to install and use it, and any configuration options that are available. This will help ensure that your plugin is accessible and useful to as many users as possible.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f3268f0-2449-4e57-b904-182c0d740ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = querying.run({\n",
    "    \"retriever\": {\"query\": query, \"top_k\": 3},\n",
    "    \"prompt_builder\": {\"query\": query},\n",
    "    \"llm\":{\"generation_kwargs\": {\"max_tokens\": 350}}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6745a9b-5765-4b2c-a582-3c65bb65ccb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, writing documentation for your plugin is highly recommended. This will help users understand how to use your plugin, provide examples of how it can be used, and give them a clear understanding of its features and capabilities. Good documentation can also help reduce support requests and make it easier for users to troubleshoot issues on their own. You can include documentation in various formats such as text files, HTML help files, or even integrated help within your plugin.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8339d52-97c2-4e14-98ce-6723ae51c76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-haystack",
   "language": "python",
   "name": "venv-haystack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
