{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626cabf4-9fd5-4f59-8eb0-f8f752273263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/prompts/prompts_rag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fb01b3-30f2-4e42-81f8-5fa4f8d2f145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install llama-index-readers-file pymupdf\n",
    "# %pip install llama-index-embeddings-openai\n",
    "# %pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9240932b-8914-44b8-a26d-4717e519ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c085d9-e3b0-4215-a34b-6b38a4063215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-111111111111111111111111111111111111111111111111'\n",
    "os.environ['OPENAI_API_BASE']='http://127.0.0.1:5000/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a024a1-d0fb-41eb-a6d1-e6532a6653cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.2-8.0bpw-h8-exl2-2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_info_url = 'http://127.0.0.1:5000/v1/internal/model/info'\n",
    "resp = requests.get(model_info_url)\n",
    "model = resp.json()['model_name']\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6913903-f08b-4251-8ff3-ddd8b1616fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70968e13-bc11-47d6-a6f0-036aa7b659ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d8d1d5-2afa-465f-bf0e-8106fca30ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import PromptTemplate\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a19d444-927e-43e1-9c9a-e91b465894d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9acfbcf6-bd31-4ca2-8018-c2df54ea4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628718bc-cb9f-4891-b494-a3d0f229ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/llama2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6275fb0-ba69-45e2-ac8e-8c1d7c661216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0107bb-4eeb-42be-b20c-146260fc2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "gpt4_llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085524bb-3f5e-407b-9b73-c30c4d227fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6cfb40-6dbb-4ce0-ab0d-ae5c22ebf770",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What are the potential risks associated with the use of Llama 2 as mentioned in the context?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d23e1b61-b7cb-461a-8be1-d29f3360e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=2, llm=gpt35_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "675be614-07d3-4b27-9d2e-1bf43f8d898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46ed6f4-e901-4a1b-87d9-7f203658167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:5000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:5000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:5000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Based on the context information provided, there are several potential risks associated with the use of Llama 2 that are discussed in the document. These risks include:\n",
      "\n",
      "1. Dataset Contamination (A.6): The document mentions the risk of dataset contamination, which could lead to biased or inaccurate model outputs.\n",
      "2. Safety Evaluation (A.4. and A.5.): The document discusses the importance of safety evaluation for Llama 2, including potential risks related to data privacy, security, and ethical considerations.\n",
      "3. Ethical Considerations and Limitations (A.2. and A.5.2): The document mentions ethical considerations and limitations related to the use of Llama 2, including potential biases and the need for responsible release strategies.\n",
      "\n",
      "Therefore, the use of Llama 2 involves risks related to dataset contamination, safety, ethical considerations, and limitations.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(query_str)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf7e0d-bb69-4fba-b2ab-d2c1ed83e86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llamaindex",
   "language": "python",
   "name": "venv-llamaindex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
